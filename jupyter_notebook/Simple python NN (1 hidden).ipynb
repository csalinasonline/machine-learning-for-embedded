{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple NN in python\n",
    "\n",
    "This NN model is a naive implementation of a Neural Network in Python and is going to be used to train and then compare and test with a few embedded platforms. The class code is taken from [here](https://github.com/llSourcell/Make_a_neural_network/blob/master/demo.py).\n",
    "\n",
    "## Prerequisites\n",
    "You need to install jupyter notebook for this example to run. The easiest way is to install miniconda and then use conda to install nupmy and jupyter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork():\n",
    "    def __init__(self, training_set_inputs, training_set_outputs):\n",
    "        \n",
    "        self.input = training_set_inputs\n",
    "        self.y = training_set_outputs\n",
    "        \n",
    "        # Seed the random number generator, so it generates the same numbers\n",
    "        # every time the program runs.\n",
    "        np.random.seed(1)\n",
    "        # Create a 3-4-1 network\n",
    "        self.weights1   = np.random.rand(self.input.shape[1],8) \n",
    "        self.weights2   = np.random.rand(8,1)\n",
    "\n",
    "    # The Sigmoid function, which describes an S shaped curve.\n",
    "    # We pass the weighted sum of the inputs through this function to\n",
    "    # normalise them between 0 and 1.\n",
    "    def __sigmoid(self, x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    # The derivative of the Sigmoid function.\n",
    "    # This is the gradient of the Sigmoid curve.\n",
    "    # It indicates how confident we are about the existing weight.\n",
    "    def __sigmoid_derivative(self, x):\n",
    "        return x * (1 - x)\n",
    "\n",
    "    # We train the neural network through a process of trial and error.\n",
    "    # Adjusting the synaptic weights each time.\n",
    "    def train(self, training_set_inputs, training_set_outputs, number_of_training_iterations):\n",
    "        for iteration in range(number_of_training_iterations):\n",
    "            # Pass the training set through the hidden layer\n",
    "            output = self.__sigmoid(np.dot(training_set_inputs, self.weights1))\n",
    "            # 2nd layer\n",
    "            output2 = self.__sigmoid(np.dot(output, self.weights2))\n",
    "\n",
    "            # Calculate the error (The difference between the desired output\n",
    "            # and the predicted output).\n",
    "            error = training_set_outputs - output2\n",
    "\n",
    "            # Multiply the error by the input and again by the gradient of the Sigmoid curve.\n",
    "            # This means less confident weights are adjusted more.\n",
    "            # This means inputs, which are zero, do not cause changes to the weights.            \n",
    "            d_weights2 = np.dot(output.T, (2*(self.y - output2) * self.__sigmoid_derivative(output2)))\n",
    "            d_weights1 = np.dot(training_set_inputs.T,  (np.dot(2*(self.y - output2) * self.__sigmoid_derivative(output2), self.weights2.T) * self.__sigmoid_derivative(output)))\n",
    "\n",
    "            # Adjust the weights.\n",
    "            self.weights1 += d_weights1\n",
    "            self.weights2 += d_weights2\n",
    "\n",
    "    # The neural network predicts.\n",
    "    def predict(self, inputs):\n",
    "        output = self.__sigmoid(np.dot(inputs, self.weights1))\n",
    "        # 2nd layer\n",
    "        return self.__sigmoid(np.dot(output, self.weights2))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create a labeled train set with data and labels.\n",
    "\n",
    "Now we need to create our input data and then label them. In this case `label` just means the output, so we have two labels 0 and 1, or you can just think of these labels as binary outputs, in this case. The data are those on the next table:\n",
    "\n",
    "D2 | D1 | D0 | Label\n",
    "-|-|-|-\n",
    "0 | 0 | 1 | 0\n",
    "1 | 1 | 1 | 1\n",
    "1 | 0 | 1 | 1\n",
    "0 | 1 | 1 | 0\n",
    "\n",
    "In Python the above table is translated to those two arrays:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_set_inputs = array([[0, 0, 1], [1, 1, 1], [1, 0, 1], [0, 1, 1]])\n",
    "training_set_outputs = array([[0, 1, 1, 0]]).T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Intialise a single neuron neural network\n",
    "\n",
    "First we need to create an `NeuralNetwork` object and initialize it. In this case initialization means that the weights will get a random value, but with using a constant seed, so the weights are re-producable per run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "neural_network = NeuralNetwork(training_set_inputs, training_set_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random starting synaptic weights:\n",
      "[[4.17022005e-01 7.20324493e-01 1.14374817e-04 3.02332573e-01\n",
      "  1.46755891e-01 9.23385948e-02 1.86260211e-01 3.45560727e-01]\n",
      " [3.96767474e-01 5.38816734e-01 4.19194514e-01 6.85219500e-01\n",
      "  2.04452250e-01 8.78117436e-01 2.73875932e-02 6.70467510e-01]\n",
      " [4.17304802e-01 5.58689828e-01 1.40386939e-01 1.98101489e-01\n",
      "  8.00744569e-01 9.68261576e-01 3.13424178e-01 6.92322616e-01]]\n"
     ]
    }
   ],
   "source": [
    "print(\"Random starting synaptic weights:\")\n",
    "print(neural_network.weights1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Train the neural network. using a training set.\n",
    "\n",
    "Now using the above training set we can train our NN. To do that we can run it 10,000 times and make small adjustments each time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New synaptic weights after training: \n",
      "\n",
      "[[ 3.22710356  3.56378795 -3.08851493 -1.87498985 -2.50247526  0.55639281\n",
      "  -2.15746908  0.2717346 ]\n",
      " [-0.02255358 -0.024517    0.24141808  0.39298636 -0.07460212  0.81562393\n",
      "  -0.08571442  0.65206476]\n",
      " [-1.26560218 -1.46057802  1.06139844  0.39626403  0.97518787  0.70940473\n",
      "   0.72903047  0.64618586]]\n"
     ]
    }
   ],
   "source": [
    "neural_network.train(training_set_inputs, training_set_outputs, 10000)\n",
    "\n",
    "print(\"New synaptic weights after training: \\n\")\n",
    "print(neural_network.weights1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Test the trained model\n",
    "\n",
    "Now that we have a trained NN, we can test it by passing input data that it doesn't know about.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# All possible inputs\n",
    "inputs = array([\n",
    "    [0,0,0],\n",
    "    [0,0,1],\n",
    "    [0,1,0],\n",
    "    [0,1,1],\n",
    "    [1,0,0],\n",
    "    [1,0,1],\n",
    "    [1,1,0],\n",
    "    [1,1,1]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0] = [0.22861484]\n",
      "[0 0 1] = [0.00310993]\n",
      "[0 1 0] = [0.18707394]\n",
      "[0 1 1] = [0.00255224]\n",
      "[1 0 0] = [0.99939804]\n",
      "[1 0 1] = [0.99730077]\n",
      "[1 1 0] = [0.99938308]\n",
      "[1 1 1] = [0.99692956]\n"
     ]
    }
   ],
   "source": [
    "for i in range(0, 8):\n",
    "    print(\"{} = {}\".format(inputs[i], neural_network.predict(inputs[i])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
